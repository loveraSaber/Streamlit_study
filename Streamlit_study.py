from langchain.agents import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os
from datetime import datetime
from langchain_core.tools import  tool
from langchain_core.prompts import PromptTemplate
from langchain.agents import AgentExecutor
load_dotenv(r"D:\Project\Python_Project\AILLM\RAG\config\.env")
os.environ['HTTP_PROXY'] = ''
os.environ['HTTPS_PROXY'] = ''
os.environ['NO_PROXY'] = 'siliconflow.cn,localhost,127.0.0.1'
api_key=os.getenv("api_key")
url_chat= os.getenv("chat_url")
embedding_url= os.getenv("embedding_url")
chat_model= os.getenv("chat_model")
embedding_model= os.getenv("embedding_model")
system_prompt="""
ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œè¯·æ ¹ç»ç”¨æˆ·çš„é—®é¢˜ï¼Œç»™å‡ºä¸“ä¸šçš„å›ç­”
"""
prompt="""ç”¨æˆ·çš„é—®é¢˜:{question}
"""
prompt_template=ChatPromptTemplate([
    ("system",system_prompt),
    ("user",prompt)
])
llm = ChatOpenAI(
    api_key=api_key,
    base_url=url_chat,
    model=chat_model,
    temperature=0.7,
)
embeddings=OpenAIEmbeddings(
    api_key=api_key,
    base_url=embedding_url,
    model=embedding_model,
)
@tool
def get_current_time(city:str="åŒ—äº¬")->str:
    """è·å–å½“å‰æ—¶é—´"""
    return f"{city} å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
prompt = PromptTemplate.from_template("""
    ä½ æ˜¯ä¸€ä¸ªå¯ä»¥è°ƒç”¨å·¥å…·çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

    ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
    {tools}

    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€è€ƒå’Œå›ç­”ï¼š

    Question: {input}
    Thought: æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    Action: é€‰æ‹©ä¸€ä¸ªå·¥å…·ï¼Œå¿…é¡»æ˜¯ [{tool_names}] ä¸­çš„ä¸€ä¸ª
    Action Input: å·¥å…·å‚æ•°
    Observation: å·¥å…·è¿”å›ç»“æœ
    Thought: æˆ‘å·²ç»çŸ¥é“ç­”æ¡ˆäº†
    Final Answer: ç»™ç”¨æˆ·çš„æœ€ç»ˆç­”æ¡ˆ

    {agent_scratchpad}
    """)
agent=create_react_agent(llm,tools=[get_current_time],prompt=prompt)
executor=AgentExecutor(agent=agent,tools=[get_current_time],verbose=True)
# result = executor.invoke({"input": "ç°åœ¨æ˜¯ä»€ä¹ˆæ—¶é—´ï¼Ÿ"})
# print(result["output"])

import streamlit as st

st.title("ğŸ¤– Agent å¯¹è¯ç³»ç»Ÿ")

# åˆå§‹åŒ–å¯¹è¯å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# è¾“å…¥æ¡†
query = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜")

if query:
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append(
        {"role": "user", "content": query}
    )
    with st.chat_message("user"):
        st.markdown(query)

    # è°ƒç”¨ Agent
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            result = executor.invoke({"input": query})
            answer = result["output"]
            st.markdown(answer)

    # ä¿å­˜åŠ©æ‰‹å›å¤
    st.session_state.messages.append(
        {"role": "assistant", "content": answer}
    )
